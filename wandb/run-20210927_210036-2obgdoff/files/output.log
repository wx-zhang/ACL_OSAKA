
load from omniglot.npy.
Num parameters in Shared       = 13.10K
Num parameters in Private      = 37.68K,  per task = 12.56K
Num parameters in Header       = 4.21K,  per task = 1.41K
Num parameters in P+H          = 41.90K
-------------------------->   Total architecture size: 55.00K parameters (220.00KB)
Num parameters in D       = 578.0
1.6039299011230468 24.2 1.6073583602905273 20.8
1.5975297927856444 30.333333333333332 1.6038084030151367 23.0
1.5887959480285645 31.666666666666668 1.599703884124756 26.8
1.5730012893676757 30.4 1.5908116340637206 26.4
1.5441222190856934 32.4 1.5807181358337403 25.2
1.545896339416504 26.866666666666667 1.5744588851928711 25.6
1.5177490234375 31.6 1.5651336669921876 26.8
1.5102669715881347 31.333333333333332 1.5661948204040528 25.0
1.5076716423034668 33.06666666666667 1.571197509765625 26.4
1.5032127380371094 31.866666666666667 1.5778204917907714 25.2
1.481546401977539 34.93333333333333 1.571963405609131 26.8
1.4884852409362792 33.666666666666664 1.587080478668213 26.0
1.4705243110656738 35.06666666666667 1.601114273071289 26.2
1.4593818664550782 35.4 1.5945033073425292 26.4
1.421333122253418 36.8 1.618246841430664 27.2
1.4048286437988282 37.6 1.6069450378417969 27.6
1.44583158493042 35.4 1.63977108001709 26.6
 lr=3.3e-021.3789578437805177 40.0 1.6452877044677734 26.2
1.3506267547607422 41.2 1.6487668991088866 28.4
1.3541921615600585 40.06666666666667 1.6587486267089844 28.2
1.3766644477844239 39.266666666666666 1.6685825347900392 27.2
1.3275879859924316 41.2 1.6849313735961915 27.4
1.3201942443847656 41.86666666666667 1.720559310913086 28.0
1.3210424423217773 41.46666666666667 1.7264860153198243 27.0
1.346494483947754 41.53333333333333 1.7171293258666993 28.4
1.3454487800598145 39.93333333333333 1.716872215270996 26.6
1.3017287254333496 42.93333333333333 1.7426305770874024 28.8
 lr=1.1e-021.291864776611328 43.53333333333333 1.7524362564086915 28.6
1.2881559371948241 43.4 1.763152503967285 29.2
1.2855634689331055 43.733333333333334 1.7754161834716797 29.6
 Dis lr=3.3e-03
1.2818380355834962 44.06666666666667 1.7872215270996095 28.2
1.2871613502502441 44.06666666666667 1.7780900955200196 28.8
1.2767133712768555 43.86666666666667 1.8061138153076173 27.8
1.2792269706726074 44.2 1.8069599151611329 28.4
1.2874951362609863 43.46666666666667 1.788213348388672 27.6
1.2688284873962403 44.8 1.826026725769043 28.8
1.263036060333252 44.46666666666667 1.8421043395996093 29.4
 lr=3.7e-031.2625296592712403 45.266666666666666 1.8398792266845703 29.2
1.2623350143432617 44.46666666666667 1.8385185241699218 29.0
1.2624272346496581 44.6 1.8505617141723634 28.4
 Dis lr=1.1e-03
1.2607020378112792 45.13333333333333 1.8517778396606446 28.0
1.2597151756286622 44.733333333333334 1.8579349517822266 28.6
1.2598767280578613 44.93333333333333 1.8727264404296875 28.2
1.258290672302246 44.6 1.866862678527832 28.2
1.2548974990844726 44.266666666666666 1.884969711303711 29.0
1.2567290306091308 44.86666666666667 1.8771522521972657 28.2
1.2573077201843261 44.6 1.8863595962524413 28.8
 lr=1.2e-031.255445957183838 44.93333333333333 1.8887813568115235 28.6
1.2537643432617187 45.2 1.8913555145263672 28.8
1.2534850120544434 45.4 1.8901548385620117 28.2
 Dis lr=3.7e-04
1.2535297393798828 45.333333333333336 1.8929338455200195 28.6
1.2521882057189941 45.46666666666667 1.8969064712524415 28.6
1.2545373916625977 45.4 1.892850112915039 28.0
1.2514272689819337 45.53333333333333 1.8955141067504884 28.2
1.25203857421875 45.666666666666664 1.8975179672241211 28.2
1.2518269538879394 45.93333333333333 1.8991558074951171 28.2
1.2519871711730957 45.733333333333334 1.8961946487426757 28.0
 lr=4.1e-041.250446605682373 45.6 1.8995126724243163 28.2
1.2497944831848145 45.53333333333333 1.9002199172973633 28.0
1.250309371948242 45.6 1.900654411315918 28.2
 Dis lr=1.2e-04
1.2498292922973633 45.733333333333334 1.901055908203125 28.0
1.2496363639831543 45.666666666666664 1.9023944854736328 28.0
1.2497293472290039 45.6 1.9023042678833009 28.0
1.2490160942077637 45.733333333333334 1.905130958557129 28.0
1.2490233421325683 45.666666666666664 1.9051223754882813 28.0
1.2489236831665038 45.666666666666664 1.9044279098510741 28.0
1.248998260498047 45.6 1.9056900024414063 28.0
 lr=1.4e-041.2490015983581544 45.53333333333333 1.906061553955078 28.0
1.2488174438476562 45.53333333333333 1.9063364028930665 28.0
1.248649501800537 45.6 1.9065942764282227 28.0
 Dis lr=4.1e-05
1.248667335510254 45.53333333333333 1.9063024520874023 28.0
1.248550033569336 45.6 1.9066709518432616 28.0
1.2485857009887695 45.46666666666667 1.9070266723632812 28.0
1.2488638877868652 45.4 1.906919288635254 28.0
1.2488114356994628 45.46666666666667 1.906968116760254 28.0
1.248477840423584 45.46666666666667 1.9072166442871095 28.0
1.2481130599975585 45.46666666666667 1.9071538925170899 28.0
 lr=4.6e-051.248469066619873 45.53333333333333 1.908193016052246 28.0
1.2483099937438964 45.46666666666667 1.9073150634765625 28.0
1.2484257698059082 45.4 1.9080617904663086 28.0
 Dis lr=1.4e-05
1.2484105110168457 45.4 1.9078290939331055 28.0
1.2484447479248046 45.4 1.907666015625 28.0
1.2484158515930175 45.4 1.9081514358520508 28.0
1.2485490798950196 45.46666666666667 1.9083141326904296 28.0
1.2484189987182617 45.4 1.908134651184082 28.0
1.2485307693481444 45.46666666666667 1.9081077575683594 28.0
1.2484732627868653 45.46666666666667 1.9082637786865235 28.0
 lr=1.5e-051.2484137535095214 45.46666666666667 1.9082149505615233 28.0
1.2483685493469239 45.46666666666667 1.9080377578735352 28.0
1.2485125541687012 45.46666666666667 1.9086822509765624 28.0
 Dis lr=4.6e-06
1.2482895851135254 45.46666666666667 1.9081783294677734 28.0
1.2485634803771972 45.46666666666667 1.9088184356689453 28.0
1.2483978271484375 45.46666666666667 1.9081718444824218 28.0
1.24837064743042 45.46666666666667 1.9079710006713868 28.0
1.248187255859375 45.46666666666667 1.9077178955078125 28.0
1.248475933074951 45.46666666666667 1.9086671829223634 28.0
1.2482979774475098 45.46666666666667 1.9078004837036133 28.0
 lr=5.1e-061.2483734130859374 45.46666666666667 1.9084074020385742 28.0
1.2484225273132323 45.46666666666667 1.9082134246826172 28.0
1.248223876953125 45.46666666666667 1.9075544357299805 28.0
 Dis lr=1.5e-06
Saving all models for task 1 ...
>>> Test on task meta - omniglot meta set: loss=1.730, acc_measure=8.00000000 <<<
pretraining done!